{
    "name": "Pod Metrics",
    "description": "Displays metrics about each pod in the cluster",
    "script": "import px\n\ndef process_stats_by_entity(start_time: int, entity: str):\n ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n Args:\n @start_time Starting time of the data to examine.\n @entity: Either pod or node_name.\n '''\n # Window size to use on time_ column for bucketing.\n ns_per_s = 1000 * 1000 * 1000\n window_ns = px.DurationNanos(10 * ns_per_s)\n\n df = px.DataFrame(table='process_stats', start_time=start_time)\n df[entity] = df.ctx[entity]\n df.timestamp = px.bin(df.time_, window_ns)\n # First calculate CPU usage by process (UPID) in each k8s_object\n # over all windows.\n df = df.groupby([entity, 'upid', 'timestamp']).agg(\n rss=('rss_bytes', px.mean),\n vsize=('vsize_bytes', px.mean),\n # The fields below are counters, so we take the min and the max to subtract them.\n cpu_utime_ns_max=('cpu_utime_ns', px.max),\n cpu_utime_ns_min=('cpu_utime_ns', px.min),\n cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n read_bytes_max=('read_bytes', px.max),\n read_bytes_min=('read_bytes', px.min),\n write_bytes_max=('write_bytes', px.max),\n write_bytes_min=('write_bytes', px.min),\n rchar_bytes_max=('rchar_bytes', px.max),\n rchar_bytes_min=('rchar_bytes', px.min),\n wchar_bytes_max=('wchar_bytes', px.max),\n wchar_bytes_min=('wchar_bytes', px.min),\n )\n # Next calculate cpu usage and memory stats per window.\n df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n df.read_bytes = df.read_bytes_max - df.read_bytes_min\n df.write_bytes = df.write_bytes_max - df.write_bytes_min\n df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n # Sum by UPID.\n df = df.groupby([entity, 'timestamp']).agg(\n cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n cpu_utime_ns=('cpu_utime_ns', px.sum),\n read_bytes=('read_bytes', px.sum),\n write_bytes=('write_bytes', px.sum),\n rchar_bytes=('rchar_bytes', px.sum),\n wchar_bytes=('wchar_bytes', px.sum),\n rss=('rss', px.sum),\n vsize=('vsize', px.sum),\n )\n df.actual_disk_read_throughput = df.read_bytes / window_ns\n df.actual_disk_write_throughput = df.write_bytes / window_ns\n df.total_disk_read_throughput = df.rchar_bytes / window_ns\n df.total_disk_write_throughput = df.wchar_bytes / window_ns\n # Now take the mean value over the various timestamps.\n df = df.groupby(entity).agg(\n cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n cpu_utime_ns=('cpu_utime_ns', px.mean),\n actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n avg_rss=('rss', px.mean),\n avg_vsize=('vsize', px.mean),\n )\n # Finally, calculate total (kernel + user time) percentage used over window.\n df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\n''' A list of pods in `namespace`.\nArgs:\n@start_time: The timestamp of data to start at.\n@namespace: The name of the namespace to filter on.\n'''\ndf = px.DataFrame(table='process_stats', start_time=$__from)\ndf.pod = df.ctx['pod_name']\ndf.node = df.ctx['node_name']\ndf.container = df.ctx['container_name']\ndf = df.groupby(['pod', 'node', 'container']).agg()\ndf = df.groupby(['pod', 'node']).agg(container_count=('container', px.count))\ndf.start_time = px.pod_name_to_start_time(df.pod)\ndf.status = px.pod_name_to_status(df.pod)\n\n\nprocess_stats = process_stats_by_entity($__from, 'pod')\noutput = process_stats.merge(df, how='inner', left_on='pod', right_on='pod',\n suffixes=['', '_x'])\n\n\npx.display(output[[$__columns]])",
    "isTabular": true,
    "columnNames": ["pod", "cpu_usage", "total_disk_read_throughput", "total_disk_write_throughput", "container_count", "node", "start_time", "status"]
}
